---
title: 凤凰架构-事务
auther: gzj
tags:
  - 凤凰架构
  - 学习笔记
categories:
  - 凤凰架构
description: >-
  日志写入commit record，整个事务就是成功的，重启后根据已经写入磁盘的日志信息恢复现场。缺陷是所有对数据的真实修改都必须发生在事务提交之后，即日志写入了commit record之后。。
abbrlink: 7a7ff038
date: 2023-11-11 09:14:09
---
## 本地事务

### 实现原子性和持久性

#### commit logging

日志写入commit record，整个事务就是成功的，重启后根据已经写入磁盘的日志信息恢复现场。

缺陷是所有对数据的真实修改都必须发生在事务提交之后，即日志写入了commit record之后。

#### write-ahead logging

按事务提交的时间点，将何时写入变动数据划分为FORCE和STEAL两个阶段

**FORCE** ：当事务提交后，要求变动的数据必须同时完成写入成为FORCE，如果不强制变动数据必须同时完成写入则成为NO-FORCE。

**STEAL** ：在事务提交前，允许变动数据提前写入成为STEAL，不允许则成为NO-STEAL。允许提前写入利于利用空闲I/O。

commit logging允许NO-FORCE，但不允许STEAL。write-ahead logging允许NO-FORCE，也允许STEAL，解决办法是增加了Undo log。

**崩溃恢复**：

- 分析阶段：从最后一次检查点开始扫描日志，找到没有End Record的事务，组成待恢复的事务集合。
- 重做阶段：该阶段依据分析阶段中产生的待恢复的事务集合来进行恢复，具体是找到所有包含commit record的日志，将这些日志修改的数据写入磁盘。
- 回滚阶段：经过分析、重做后剩余的待恢复事务集合，就是需要回滚的事务，根据Undo log，将已经写入磁盘的信息重新改回去。

> 我理解write-ahead logging相比commit logging的优点是可以将一个大事务的每一次操作都慢慢写到磁盘，因为commit logging必须把所有的修改都写到commit record后，具体的改动才能一股脑写进去。

### 实现隔离性

隔离性保证了每个事务各自的读、写的数据相互独立，不会彼此影响。

现代数据库均提供了以下三种锁：

- **写锁**：数据有加写锁，只有持有写锁的事务才能对数据进行写入操作，数据加持着写锁时，其他事务不能写入数据，也不能加读锁。
- **读锁**：多个事务可以加多个读锁，数据加读锁后不能加写锁。对于持有读锁的事务，如果该数据只有他自己的一个事务加了读锁，允许升级为写锁。
- **范围锁**：对某个范围直接加排它锁，在这个范围内的数据不能被写入。

#### 串行化访问

提供了最高强度的隔离性，分为加锁和解锁两阶段去处理读锁、写锁和数据之间的关系，称为两阶段锁。

#### 可重复读

可重复读比可串行化弱化的地方在于幻读问题（在事务执行过程中，两个完全相同的范围查询得到不同的结果集）。可重复读对事务所涉及的数据加读锁和写锁，且一直持有至事务结束，但不再加范围锁。

具体的数据库不一定完全遵照ARIES理论去实现。MySQL/InnoDB的默认隔离级别是可重复读，但它在只读事务（一个事务中只有查询语句）中可完全避免幻读问题。

#### 读已提交

读已提交对事务涉及的数据加的写锁会一直持续到事务结束，但加的读锁会在查询操作完成后马上释放。读已提交比可重复读弱化的地方在于不可重复读问题（事务执行时，对同一数据的两次查询得到不同的结果）。

#### 读未提交

读未提交指挥对事务设计的数据加写锁，且一直持续到事务结束，完全不加读锁。读未提交比读已提交弱化的地方在于脏读问题。

>不同隔离级别以及幻读、不可重复读、脏读等问题都只是表面现象，是各种锁在不同加锁时间上的组合应用所产生的结果，以锁为手段来实现隔离性才是数据库表现出不同隔离级别的根本原因。

#### MVCC

除了都以锁来实现外，以上四种隔离级别还有另外一个共同特点，就是幻读、不可重复读、脏读等问题都是由于一个事务在读数据的过程中，受另外一个写数据的事务影响而破坏了隔离性。针对“一个事务读+另一个事务写”的隔离问题，MVCC的无锁优化方案被主流的数据库广泛采用。

MVCC是一种读取优化策略，它的“无锁”特指读取时不需要加锁。

MVCC的基本思路是对数据库的任何修改都不会直接覆盖之前的数据，而是产生一个新版本与老版本共存。版本可以理解为数据库中每一行记录都存在两个看不见的字段：CREATE_VERSION和DELETE_VERSION，这两个字段记录的值都是事务ID。事务ID是一个全局严格递增的值，根据以下规则写入数据：

- 插入数据：CREATE_VERSION记录插入数据的事务ID，DELETE_VERSION为空。
- 删除数据：DELETE_VERSION记录删除数据的事务ID，CREATE_VERSION为空。
- 修改数据：即“删除旧数据，插入新数据”的组合，将原有数据复制一份，原有数据的DELETE_VERSION记录修改数据的事务ID，CREATE_VERSION为空。复制后的新数据CREATE_VERSION记录修改数据的事务ID，DELETE_VERSION为空。

另一个事务读取这些发生变化的数据，根据隔离级别决定读取哪个版本的数据。

- 可重复读：总是读取CREATE_VERSION小于等于当前事务ID的记录，数据有多个版本取最新的。
- 读已提交：总是读最新的版本即可。

## 全局事务

全局事务指的是单个服务使用多个数据源场景的事务解决方案。

#### 两阶段提交

**准备阶段**：协调者询问事务的所有参与者是否准备好提交，参与者如果已经准备好提交则回复Prepared，否则回复Non-Prepared。准备好的意思是在重做日志中记录全部事务提交操作所要作的内容，它与本地事务中真正提交的区别只是暂不写入最后一条commit record而已。当前状态仍继续持有锁。

**提交阶段**：如果协调者收到所有事务参与者回复的Prepared消息，则自己先在本地持久化事务的完成状态置为commit，然后向所有参与者发送commit指令。如果任意一个参与者回复了Non-Prepared消息，或者超时未回复，协调者将自己完成事务状态置为abort，再向所有参与者发送abort指令，让参与者进行回滚。

>两阶段提交能够成功保证一致性还需要其他的前提条件：
>
>必须假设网络在提交阶段的短时间内是可靠的，提交阶段不会丢消息。
>
>必须假设因为网络分区，机器崩溃等原因导致失联的节点最终能够恢复，不会永久处于失联状态。
>
>且上述的协调者、参与者通常都是数据库自己扮演，不需要应用程序介入。协调者一般是选举产生。

**缺点**：

- 单点问题：协调者宕机的话，所有参与者都必须一直等待。
- 性能问题：所有参与者都被绑定为一个统一调度的整体，期间要两次远程调用，三次数据持久化（准备阶段写重做日志，协调者做状态持久化，提交阶段在日志写提交记录）
- 一致性风险：前提条件不成立时，仍会有一致性问题。

>FLP不可能原理：
>
>如果宕机最后不能恢复，那就不存在任何一种分布式协议可以正确地达成一致性结果。

#### 三阶段提交

由于两阶段提交存在协调者的单点问题和准备阶段的性能问题，发展出了三阶段提交。

三阶段提交把原来的两阶段提交的准备阶段再细分为两个阶段，即CanCommit、PreCommit，把提交阶段改为DoCommit。CanCommit是询问阶段，协调者让每个参与的数据库根据自身状态，评估该事务是否有可能顺利完成。

在事务需要回滚的场景中，三阶段提交比两阶段提交的性能好很多，但正常情况下，两者的性能都很差，三阶段提交多一次询问，性能还要稍微更差。

事务失败回滚的概率变小，三阶段提交如果PreCommit后协调者宕机，参与者默认是提交事务，避免了协调者单点问题。

## 分布式事务

分布式事务指的是多个服务同时访问多个数据源的事务处理机制。

#### CAP和ACID

CAP指的是一个分布式系统，在涉及共享数据问题时，以下三个特性最多只能同时满足两个：

- 一致性 C：数据在任何时刻，任何分布式节点所看到的都是符合预期的。
- 可用性 A：代表系统不间断的提供服务的能力。
- 分区容忍性 P：分布式环境中部分节点因网络原因而彼此失联后，系统扔能正确提供服务的能力。

#### 可靠事件队列

BASE理论是由eBay工程师提出，是对可用性和一致性的权衡。BASE是由 Basically Available(基本可用)，Soft state（软状态）,和 Eventually consistent（最终一致性）三个短语的缩写。

**Basically Available(基本可用)**：通过延迟响应，流量削峰等手段来保障系统的核心功能的正常，从而实现基本可用。

**Eventually consistent(最终一致性)** ：我们不能随时都保障数据的一致，所以我们有了数据的中间状态，即软状态，经过一定时间后，数据最终回归于最终一致。

**Soft state(软状态)** ：软状态故名思意就是可以变动的状态，强调的是数据状态处于一种中间状态。

可靠事件队列是依靠不断重试的方案来保证可靠性。

#### TCC事务

TCC是一种业务侵入式的事务方案。分为三阶段：

1. Try：尝试执行阶段，完成所有业务可执行性的检查，并预留好全部业务需要用到的业务资源（锁资源）。
2. Confirm：确认执行阶段，不进行任何业务检查，直接使用Try阶段准备的资源完成业务处理。可能会重复执行，需要保证幂等。
3. Cancel：取消执行阶段，释放Try阶段预留的资源。

#### SAGA事务

TCC事务有个缺点，是业务侵入性很强，必须预先锁好资源，假如无法锁定资源，就无法实现了。

SAGA事务是一种将大事务拆分成若干小事务的设计模式。

SAGA 由两部分操作组成。

- 大事务拆分若干个小事务，将整个分布式事务 T 分解为 n 个子事务，命名为 T1，T2，…，Ti，…，Tn。每个子事务都应该是或者能被视为是原子行为。如果分布式事务能够正常提交，其对数据的影响（最终一致性）应与连续按顺序成功提交 Ti等价。
- 为每一个子事务设计对应的补偿动作，命名为 C1，C2，…，Ci，…，Cn。Ti与 Ci必须满足以下条件：
  - Ti与 Ci都具备幂等性。
  - Ti与 Ci满足交换律（Commutative），即先执行 Ti还是先执行 Ci，其效果都是一样的。
  - Ci必须能成功提交，即不考虑 Ci本身提交失败被回滚的情形，如出现就必须持续重试直至成功，或者要人工介入。

如果 T1到 Tn均成功提交，那事务顺利完成，否则，要采取以下两种恢复策略之一：

- **正向恢复**（Forward Recovery）：如果 Ti事务提交失败，则一直对 Ti进行重试，直至成功为止（最大努力交付）。这种恢复方式不需要补偿，适用于事务最终都要成功的场景，譬如在别人的银行账号中扣了款，就一定要给别人发货。正向恢复的执行模式为：T1，T2，…，Ti（失败），Ti（重试）…，Ti+1，…，Tn。
- **反向恢复**（Backward Recovery）：如果 Ti事务提交失败，则一直执行 Ci对 Ti进行补偿，直至成功为止（最大努力交付）。这里要求 Ci必须（在持续重试后）执行成功。反向恢复的执行模式为：T1，T2，…，Ti（失败），Ci（补偿），…，C2，C1。

























